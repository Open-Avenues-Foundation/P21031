# Phase 2: Model design - 4 courses + videos

In this phase, you will learn different approaches to design a model that will rely on unclassified data. You will learn the basics of topic classification, unsupervised sentence classification, and vectorization of words. After this phase, you will be able to apply these techniques in different fields of sentence classification.

From this phase, you will create the following code/system:
- A prediction pipeline that transforms a company description and predicts its industry.
- Different models design on how to represent and classify information using words.
- Evaluate the performance of your model and understanding the weaknesses and advantages for each of them.

### Week 1 -- Video link:
[<img src="https://deepnote.com/buttons/try-in-a-jupyter-notebook-white-small.svg">](https://deepnote.com/project/P21031-Industry-project-S1FIR-FFTlGcJuMGQp1GMQ/%2FP21031%2Fphase2%2Flesson_1.ipynb)
### Data representation from text
For this first week, we will learn the basics of data representation. You will discover several techniques to represent a document into something that a model can process—learning from the primary count vectorizer to the more complex Tfidf, their differences, and what makes each of them better for a specific use case. We will also cover some data cleaning approaches to avoid treating noise or unnecessary information in our observations.

Keywords: *tokenization*, *stop words*, *feature representation*, *count vectorizer*, *tfidf*, *regex*, *feature selection*

### Week 2 -- Video link:
[<img src="https://deepnote.com/buttons/try-in-a-jupyter-notebook-white-small.svg">](https://deepnote.com/project/P21031-Industry-project-S1FIR-FFTlGcJuMGQp1GMQ/%2FP21031%2Fphase2%2Flesson_2.ipynb)
### Unsupervised word representation

For this second week, we will learn how to represent a word so that you can treat it as a piece of knowledge—learning the basics of feature representation. In addition, this session will help you learn a famous model called word2vec, which enables you to understand much more about the word based on its context. 

Keywords: *word2vec*, *feature selection*, *feature representation*, *embedding space*

### Week 3 -- Video link:
[<img src="https://deepnote.com/buttons/try-in-a-jupyter-notebook-white-small.svg">](https://deepnote.com/project/P21031-Industry-project-S1FIR-FFTlGcJuMGQp1GMQ/%2FP21031%2Fphase2%2Flesson_3.ipynb)
### Model design

In the third week, we will learn how to bring all the pieces together—assembling what we learned so far into our problem. Then, we will design the pipeline that will create our final classification model. Finally, you will try to find all the system's limitations and new ideas from the final result. We will go through the assignment results and some of your questions after designing your model during this lesson.

Keywords: *model design*, *assignment*, *linear algebra*, *embedding space*

### Week 4 -- Video link:
[<img src="https://deepnote.com/buttons/try-in-a-jupyter-notebook-white-small.svg">](https://deepnote.com/project/P21031-Industry-project-S1FIR-FFTlGcJuMGQp1GMQ/%2FP21031%2Fphase2%2Flesson_4.ipynb)
### What is done in the industry?

During this final week of the program, I will walk you through alternatives to the model we designed and see how it compares. Next, we will cover old unsupervised methods that are successful in modeling topics in a vast set of observations. Then, we will see how to compare performances and find the advantages and weaknesses of each model. Finally, I will present to you what is currently done in Data science, especially in Natural Language Processing, to classify documents without labels.

Keywords: *LSA*, *LDA*, *research*, *results*, *benchmark*