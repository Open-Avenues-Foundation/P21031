{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Session 1 - Data Cleaning and Normalization\n\nIn this session, we will learn the basics of data cleaning and normalization. You will discover several techniques to take raw data and transform it as significant information\n\nKeywords: *tokenization*, *stop words*, *regex*",
   "metadata": {
    "cell_id": "00000-aff22b2b-fae2-4d26-8277-68aad28289b8",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Overview of the project and the data\nThis project stage focuses on building a classification model to assign a company to its industry using the company description scraped online.\n\nWe will be discovering how to represent the information to be understood by the machine quickly and find the best method to gain accuracy. You will develop an independent pipeline that will take text as input and give you the closer industry related to your input information during this stage. \n\nFor the presentation of the different technique we will be using a famous dataset called 20NewsGroup. You role will be to apply all the techniques learned during that process and aplpy them to the Fama industry data",
   "metadata": {
    "cell_id": "00001-dac5e4b8-db3c-4b9c-88c3-44fc5c07d39c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Let's first look at the dataset that we will be using during this whole course using a famous library called [Pandas](https://www.educba.com/what-is-pandas/):",
   "metadata": {
    "cell_id": "00002-cea02a32-9418-4dea-9870-baf616bcffff",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00003-b857e685-ecfa-4baa-a1dd-cb7bae983927",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a1e0e451",
    "execution_start": 1634161207516,
    "execution_millis": 2262232,
    "deepnote_cell_type": "code"
   },
   "source": "#Let's import the library\nimport pandas as pd #We define an alias for future usage of the library\nimport random\nimport regex as re\nimport unicodedata\nimport nltk\nimport spacy\nimport string",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00004-d76c808b-6e75-4cd4-8fa9-d0694561b286",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "681169b1",
    "execution_start": 1634158954914,
    "execution_millis": 8401,
    "deepnote_cell_type": "code"
   },
   "source": "#We will import and read our dataset using pandas\nfrom sklearn.datasets import fetch_20newsgroups\ndata = fetch_20newsgroups()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00005-e28f4272-a53b-483b-8b30-ee8232fcd3f0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "81c9ef30",
    "execution_start": 1634158963315,
    "execution_millis": 9,
    "deepnote_cell_type": "code"
   },
   "source": "dataset = pd.DataFrame({\"text\": data[\"data\"], \"label\": data[\"target\"]})",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00005-cc468411-3227-4e2a-98be-128354b34be5",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f7c86a12",
    "execution_start": 1634158963331,
    "execution_millis": 49,
    "deepnote_cell_type": "code"
   },
   "source": "#Let's now read look at a sample of the data\ndataset.head()",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 4,
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "row_count": 5,
       "column_count": 2,
       "columns": [
        {
         "name": "text",
         "dtype": "object",
         "stats": {
          "unique_count": 5,
          "nan_count": 0,
          "categories": [
           {
            "name": "From: lerxst@wam.umd.edu (where's my thing)\nSubject: WHAT car is this!?\nNntp-Posting-Host: rac3.wam.umd.edu\nOrganization: University of Maryland, College Park\nLines: 15\n\n I was wondering if anyone out there could enlighten me on this car I saw\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\nthe front bumper was separate from the rest of the body. This is \nall I know. If anyone can tellme a model name, engine specs, years\nof production, where this car is made, history, or whatever info you\nhave on this funky looking car, please e-mail.\n\nThanks,\n- IL\n   ---- brought to you by your neighborhood Lerxst ----\n\n\n\n\n",
            "count": 1
           },
           {
            "name": "From: guykuo@carson.u.washington.edu (Guy Kuo)\nSubject: SI Clock Poll - Final Call\nSummary: Final call for SI clock reports\nKeywords: SI,acceleration,clock,upgrade\nArticle-I.D.: shelley.1qvfo9INNc3s\nOrganization: University of Washington\nLines: 11\nNNTP-Posting-Host: carson.u.washington.edu\n\nA fair number of brave souls who upgraded their SI clock oscillator have\nshared their experiences for this poll. Please send a brief message detailing\nyour experiences with the procedure. Top speed attained, CPU rated speed,\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\nfunctionality with 800 and 1.4 m floppies are especially requested.\n\nI will be summarizing in the next two days, so please add to the network\nknowledge base if you have done the clock upgrade and haven't answered this\npoll. Thanks.\n\nGuy Kuo <guykuo@u.washington.edu>\n",
            "count": 1
           },
           {
            "name": "3 others",
            "count": 3
           }
          ]
         }
        },
        {
         "name": "label",
         "dtype": "int64",
         "stats": {
          "unique_count": 4,
          "nan_count": 0,
          "min": "1",
          "max": "14",
          "histogram": [
           {
            "bin_start": 1,
            "bin_end": 2.3,
            "count": 1
           },
           {
            "bin_start": 2.3,
            "bin_end": 3.6,
            "count": 0
           },
           {
            "bin_start": 3.6,
            "bin_end": 4.9,
            "count": 2
           },
           {
            "bin_start": 4.9,
            "bin_end": 6.2,
            "count": 0
           },
           {
            "bin_start": 6.2,
            "bin_end": 7.5,
            "count": 1
           },
           {
            "bin_start": 7.5,
            "bin_end": 8.8,
            "count": 0
           },
           {
            "bin_start": 8.8,
            "bin_end": 10.1,
            "count": 0
           },
           {
            "bin_start": 10.1,
            "bin_end": 11.4,
            "count": 0
           },
           {
            "bin_start": 11.4,
            "bin_end": 12.700000000000001,
            "count": 0
           },
           {
            "bin_start": 12.700000000000001,
            "bin_end": 14,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows_top": [
        {
         "text": "From: lerxst@wam.umd.edu (where's my thing)\nSubject: WHAT car is this!?\nNntp-Posting-Host: rac3.wam‚Ä¶",
         "label": 7,
         "_deepnote_index_column": 0
        },
        {
         "text": "From: guykuo@carson.u.washington.edu (Guy Kuo)\nSubject: SI Clock Poll - Final Call\nSummary: Final c‚Ä¶",
         "label": 4,
         "_deepnote_index_column": 1
        },
        {
         "text": "From: twillis@ec.ecn.purdue.edu (Thomas E Willis)\nSubject: PB questions...\nOrganization: Purdue Uni‚Ä¶",
         "label": 4,
         "_deepnote_index_column": 2
        },
        {
         "text": "From: jgreen@amber (Joe Green)\nSubject: Re: Weitek P9000 ?\nOrganization: Harris Computer Systems Di‚Ä¶",
         "label": 1,
         "_deepnote_index_column": 3
        },
        {
         "text": "From: jcm@head-cfa.harvard.edu (Jonathan McDowell)\nSubject: Re: Shuttle Launch Question\nOrganizatio‚Ä¶",
         "label": 14,
         "_deepnote_index_column": 4
        }
       ],
       "rows_bottom": null
      },
      "text/plain": "                                                text  label\n0  From: lerxst@wam.umd.edu (where's my thing)\\nS...      7\n1  From: guykuo@carson.u.washington.edu (Guy Kuo)...      4\n2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...      4\n3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...      1\n4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...     14",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "There are **2** features in this dataset:\nThe text of the new article and the category of that new article.\n\nLet's look at the first text and see how we can clean it:\n",
   "metadata": {
    "cell_id": "00006-26c90740-6047-4c8f-be9d-1f99732c16d7",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00008-8f5049b4-76b7-4fc5-b9ce-0b7bf22d7c69",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "882ee06",
    "execution_start": 1634159169467,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "sentences = dataset[\"text\"].values",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-37afea3b-e4c9-4fb2-a5e0-7590f6e297b3",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "79cc941f",
    "execution_start": 1634159477502,
    "execution_millis": 21,
    "deepnote_cell_type": "code"
   },
   "source": "sentence = random.choice(sentences)\nprint(sentence)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "From: tedr@athena.cs.uga.edu (Ted Kalivoda)\nSubject: Re: Atheist's views on Christianity (was: Re: \"Accepting Jeesus in your heart...\")\nOrganization: University of Georgia - UCNS\nLines: 32\n\nIn article <Apr.19.05.13.48.1993.29266@athos.rutgers.edu>,\nkempmp@phoenix.oulu.fi (Petri Pihko) wrote:\n> \n> Jason Smith (jasons@atlastele.com) wrote: \n \n> Another answer is that God is the _source_ of all existence.\n> This sounds much better, but I am tempted to ask: Does God\n> Himself exist, then? If God is the source of His own existence,\n> it can only mean that He has, in terms of human time, always\n> existed. But this is not the same as the source of all existence.\n> This argument sounds like God does not exist, but meta-exists,\n> and from His meta-existent perspective, He created existence.\n> I think this is actually a nonsolution, a mere twist of words.\n\nAlways existing and being the source of the existence of all other beings\nis not problematic.\n\nBut, as you put, Being the source of \"all\" existence, including one's own,\nwould mean that God came from nothing, a concept alien to Christianity and\nTheism.  It is better to understand the classical concepts of Necessary and\nContingent existence.  God exists necessarily, always.  God created\ncontingent beings.  This is a coherent solution to existence, so long as\nthe concept of God is coherent.\n \n> The best answer I have heard is that human reasoning is incapable\n> of understanding such questions. Being an atheist myself, I do not\n> accept such answers, since I do not have any other methods.\n\nNot a very good answer.  If reason cannot by any means understand something\nthen it is likely that \"it\" is a null concept, something not in reality.\n\nTed Kalivoda\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "[10 min] Let's list some information that might not be relevant to understand the category of the new article:",
   "metadata": {
    "tags": [],
    "cell_id": "00009-a2458973-e149-4739-98d7-e3c4f67b43e2",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "- Emails adresses\n- Common words (adjectives)\n- Empty spaces\n- Punctuation\n- Phone numbers\n- Date",
   "metadata": {
    "tags": [],
    "cell_id": "00010-ce8e66ef-65f9-4b84-9394-d5ba6e90a370",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Remove unwanted information",
   "metadata": {
    "tags": [],
    "cell_id": "00012-6342c3ae-a581-48a2-914c-937d1ac9887d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "To remove these unrelevant information we can use several techniques that we will cover in this course\n\n## Regex \nWe can filter and clean the text using regular expressions. Short for regular expression, a regex is a string of text that allows you to create patterns that help match, locate, and manage text.",
   "metadata": {
    "cell_id": "00007-99010e64-874a-4a4d-8a16-7c27ca00830a",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Here is an example:\n\n![Regular expression](https://www.computerhope.com/jargon/r/regular-expression.gif)",
   "metadata": {
    "cell_id": "00008-4c57c948-702c-4de5-8327-a4c4cc942204",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "[10 min] Let's work together on building and understanding the email regex:",
   "metadata": {
    "tags": [],
    "cell_id": "00015-0abaf739-36b8-4366-b306-886c29b7a48a",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00015-34e5ad79-3ac9-4216-910a-ec7b8360405c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2ff5290c",
    "execution_start": 1634161678383,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "pattern = \"[\\w.-]+@[\\w.]+\\.[a-zA-Z]{2,4}\"\nexample = \"We want to extract this email: antoine-121.gargot@hawk.iit.edu\"\n# re.findall(pattern, example)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00017-7fa9acc6-4bd9-4229-ad0f-9dcc23b66e3e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9749c1de",
    "execution_start": 1634161718295,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "email_regex = re.compile(pattern)\nsentence = email_regex.sub(' ', sentence)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "In our case, we don't want to use numbers or special characters because this information can be utilized in any newpaper and doesn't seem to be a strong marker of knowledge. We can apply a regex function to the dataset such as follow:\n\n[Regex Cheatsheet](https://medium.com/factory-mind/regex-tutorial-a-simple-cheatsheet-by-examples-649dc1c3f285)\n\nUseful to remove using Regex\n- HTML\n- URLs\n- Unicode (emoji ü§©) [Emojis table](http://www.unicode.org/emoji/charts/full-emoji-list.html)\n- Hashtags\n- Phone numbers",
   "metadata": {
    "cell_id": "00009-d055c751-8592-4a23-b18b-5503136733d4",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00018-51fdb5c9-678e-4c07-a5c6-cd3035d37f20",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4cdfa63e",
    "execution_start": 1634161763442,
    "execution_millis": 4,
    "deepnote_cell_type": "code"
   },
   "source": "def remove_html(text):\n    html_pattern = re.compile('<.*?>')\n    return html_pattern.sub(r'', text)\n\nexample = \"\"\"\n<div>This is a test</div>\n\"\"\"\nsentence = remove_html(sentence)\n\ndef remove_urls(text):\n    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_pattern.sub(r'', text)\n\nsentence = remove_urls(sentence)\n\ndef remove_emoji(string):\n    emoji_pattern = re.compile(\"[\"\n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n        u\"\\U00002702-\\U000027B0\"\n        u\"\\U000024C2-\\U0001F251\"\n        \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', string)\n\nexample = \"This is a test üòè üôÉ ü§ì\"\nsentence = remove_emoji(sentence)\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00019-13b11b9f-46ef-4b93-b373-3afd67b77cc6",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a6e18b9f",
    "execution_start": 1634160945481,
    "execution_millis": 2308,
    "deepnote_cell_type": "code"
   },
   "source": "\"This is a test ü§ì, üôÉ\".encode(\"unicode\")",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "LookupError",
     "evalue": "unknown encoding: unicode",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-fac91bce8b88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\"This is a test ü§ì, üôÉ\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unicode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m: unknown encoding: unicode"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## String operation",
   "metadata": {
    "tags": [],
    "cell_id": "00016-b56efdf3-afde-4e5d-8af6-363654639b6c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Useful to remove/ change using string operation\n\n- Number\n- Punctuation\n- Lower case",
   "metadata": {
    "tags": [],
    "cell_id": "00016-813fbd4b-e2c6-4259-837a-8e4e1ace5a1c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00021-c94a6c07-dcfa-4124-b76b-7e8a4080a36e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2a559df6",
    "execution_start": 1634161291462,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "PUNCT_TO_REMOVE = string.punctuation\ndef remove_punctuation(text):\n    \"\"\"custom function to remove the punctuation\"\"\"\n    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00021-e6dd0ac4-2e49-4392-8453-6bd1cbc6b28a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7d72172b",
    "execution_start": 1634161790571,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "sentence = sentence.lower()\nsentence = remove_punctuation(sentence)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00025-f56595cd-b117-451f-b996-8e0c145313b7",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "75b49f1a",
    "execution_start": 1634162853973,
    "execution_millis": 9,
    "deepnote_cell_type": "code"
   },
   "source": "# For numbers\nsentence = \"this is a test 1231341234123\"\n''.join([i for i in sentence if not i.isdigit()])",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 72,
     "data": {
      "text/plain": "'this is a test '"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00025-43b2de2f-746c-4c54-9f7a-63f50fdaf2c0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4686b746",
    "execution_start": 1634161800049,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "print(sentence)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "from   ted kalivoda\nsubject re atheists views on christianity was re accepting jeesus in your heart\norganization university of georgia  ucns\nlines 32\n\nin article \n  petri pihko wrote\n \n jason smith   wrote \n \n another answer is that god is the source of all existence\n this sounds much better but i am tempted to ask does god\n himself exist then if god is the source of his own existence\n it can only mean that he has in terms of human time always\n existed but this is not the same as the source of all existence\n this argument sounds like god does not exist but metaexists\n and from his metaexistent perspective he created existence\n i think this is actually a nonsolution a mere twist of words\n\nalways existing and being the source of the existence of all other beings\nis not problematic\n\nbut as you put being the source of all existence including ones own\nwould mean that god came from nothing a concept alien to christianity and\ntheism  it is better to understand the classical concepts of necessary and\ncontingent existence  god exists necessarily always  god created\ncontingent beings  this is a coherent solution to existence so long as\nthe concept of god is coherent\n \n the best answer i have heard is that human reasoning is incapable\n of understanding such questions being an atheist myself i do not\n accept such answers since i do not have any other methods\n\nnot a very good answer  if reason cannot by any means understand something\nthen it is likely that it is a null concept something not in reality\n\nted kalivoda\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Stop Words\n\nStop words are a set of common words in the language or the domain you are working on. We consider that stopwords will not play an essential role in classifying or document using keywords and will add unnecessary features to our documents.\n\nLet's look at some of the basic words:\n\n",
   "metadata": {
    "cell_id": "00010-4e38056a-f34f-403d-be3a-30d1c0c95766",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00021-64141d6b-20c4-4296-85a8-d03eeb9dd2b1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "996235c1",
    "execution_start": 1634161609774,
    "execution_millis": 78,
    "deepnote_cell_type": "code"
   },
   "source": "with open(\"../assets/stopwords.txt\", \"r\") as f_in:\n    stop_words = [i.strip().lower() for i in f_in.readlines()]",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00022-870046e3-aba7-4258-ad1f-72fb06bcbeb8",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ee1a7b",
    "execution_start": 1634161886075,
    "execution_millis": 10,
    "deepnote_cell_type": "code"
   },
   "source": "print(\" \".join([token for token in sentence.split(\" \") if token not in stop_words]))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "  ted kalivoda\nsubject atheists views christianity accepting jeesus heart\norganization university georgia  ucns\nlines 32\n\nin article \n  petri pihko wrote\n \n jason smith   wrote \n \n another answer god source existence\n sounds much better tempted ask god\n exist god source existence\n mean terms human time always\n existed source existence\n argument sounds like god exist metaexists\n metaexistent perspective created existence\n think actually nonsolution mere twist words\n\nalways existing source existence beings\nis problematic\n\nbut put source existence including ones own\nwould mean god came nothing concept alien christianity and\ntheism  better understand classical concepts necessary and\ncontingent existence  god exists necessarily always  god created\ncontingent beings  coherent solution existence long as\nthe concept god coherent\n \n best answer heard human reasoning incapable\n understanding questions atheist not\n accept answers since methods\n\nnot good answer  reason cannot means understand something\nthen likely null concept something reality\n\nted kalivoda\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Normalization\n\nThe objective of normalizing a text is to remove general as many words as possible in the same feature. Normalization is always optional but can be really useful when you will be working with more traditional machine learning algorithms.\n\n### Removing accent from the text\n\nWhen dealing with online texts, you will have to remove some accented characters from some letters, resulting from wrong encoding when scraping the information.",
   "metadata": {
    "tags": [],
    "cell_id": "00015-df6f0fe0-e021-40a5-8d99-7f28725a40fe",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00024-fe77984b-f92d-4aec-808a-bfbb6e3f99e0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b3d3137",
    "execution_start": 1634161962744,
    "execution_millis": 15,
    "deepnote_cell_type": "code"
   },
   "source": "text = unicodedata.normalize('NFKD', 'S√≥mƒõ √Åccƒõntƒõd tƒõxt üôÉ').encode('ascii', 'ignore').decode('utf-8', 'ignore')\nprint(text)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Some Accented text \n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "After dealing with actual characters, you can look at words. There are several techniques that can be used to reduce the number of feature you will have to represent similar words\n\n### Stemmer\n\nFirst, let's look at stemming.\nStemming is the process of reducing inflected words to their word stem or root form\n\nFor example:\n\n![play](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1539984207/stemminglemmatization_n8bmou.jpg)\n\nThere are several type of stemming algorithm, let's look at one of them, the Porter stemmer.\n\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00015-f696330a-22ce-44ce-974c-43b8ebc1a315",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00026-9c60972c-a5d4-41d6-a31b-c9ccbe3370d8",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e7579e0b",
    "execution_start": 1634158963420,
    "execution_millis": 71,
    "deepnote_cell_type": "code"
   },
   "source": "stemmer = nltk.stem.PorterStemmer()\n\nwords = [\"playing\", \"plays\", \"played\"]\nwords = [stemmer.stem(word) for word in words]\nprint(words)\n\n#Will not affect\nprint(stemmer.stem(\"is\"))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "['play', 'play', 'play']\nis\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Lemmatization\n\n\nLemmatization is almost similar to Stemmer, in regards that it will reduce the inflected words. But it differs in the way that it makes sure that the root word belongs to the language and will take the type of word into account (verb, adjective, noun...). In order to improve the performances, you might consider using a model called POS model (Part of Speech Tagging).\n\nBecause of this specificity, the lemmatizer will be slower than regular stemming.",
   "metadata": {
    "tags": [],
    "cell_id": "00026-58e78e60-76d0-4703-8a0b-6681a04f43bd",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00028-af89c310-0908-47c4-b593-1ec82eded9a5",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ec1540c",
    "execution_start": 1634158963427,
    "execution_millis": 427,
    "deepnote_cell_type": "code"
   },
   "source": "nltk.download('wordnet')\n\nlemmatizer = nltk.stem.WordNetLemmatizer()",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "[nltk_data] Downloading package wordnet to /root/nltk_data...\n[nltk_data]   Unzipping corpora/wordnet.zip.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00029-dc637631-b04c-4196-b8be-ad2f7fd59e93",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "74d3caf4",
    "execution_start": 1634158963895,
    "execution_millis": 1669,
    "deepnote_cell_type": "code"
   },
   "source": "print(lemmatizer.lemmatize('is', 'v'))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "be\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00030-bba5c26c-f250-4558-8b36-4a48d619570d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "49f1997e",
    "execution_start": 1634158965554,
    "execution_millis": 9848,
    "deepnote_cell_type": "code"
   },
   "source": "!python -m spacy download en_core_web_sm >> /dev/null",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "2021-10-13 21:02:47.520184: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2021-10-13 21:02:47.520227: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00030-922db547-0df1-4e68-b232-805185b14656",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "27b93cd1",
    "execution_start": 1634162207134,
    "execution_millis": 425,
    "deepnote_cell_type": "code"
   },
   "source": "# Using another library\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n\ndoc = nlp(sentence)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00032-afd456f4-7418-4cb0-b63b-a11cf1153b5a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4686b746",
    "execution_start": 1634162231676,
    "execution_millis": 14,
    "deepnote_cell_type": "code"
   },
   "source": "print(sentence)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "from   ted kalivoda\nsubject re atheists views on christianity was re accepting jeesus in your heart\norganization university of georgia  ucns\nlines 32\n\nin article \n  petri pihko wrote\n \n jason smith   wrote \n \n another answer is that god is the source of all existence\n this sounds much better but i am tempted to ask does god\n himself exist then if god is the source of his own existence\n it can only mean that he has in terms of human time always\n existed but this is not the same as the source of all existence\n this argument sounds like god does not exist but metaexists\n and from his metaexistent perspective he created existence\n i think this is actually a nonsolution a mere twist of words\n\nalways existing and being the source of the existence of all other beings\nis not problematic\n\nbut as you put being the source of all existence including ones own\nwould mean that god came from nothing a concept alien to christianity and\ntheism  it is better to understand the classical concepts of necessary and\ncontingent existence  god exists necessarily always  god created\ncontingent beings  this is a coherent solution to existence so long as\nthe concept of god is coherent\n \n the best answer i have heard is that human reasoning is incapable\n of understanding such questions being an atheist myself i do not\n accept such answers since i do not have any other methods\n\nnot a very good answer  if reason cannot by any means understand something\nthen it is likely that it is a null concept something not in reality\n\nted kalivoda\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00031-a8605276-aff1-47d0-a47a-f44159520885",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3c8f83e6",
    "execution_start": 1634162253772,
    "execution_millis": 10,
    "deepnote_cell_type": "code"
   },
   "source": "print(\" \".join([token.lemma_ for token in doc]))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "from    ted kalivoda \n subject re atheist view on christianity be re accept jeesus in your heart \n organization university of georgia   ucns \n line 32 \n\n in article \n   petri pihko write \n \n  jason smith    write \n \n  another answer be that god be the source of all existence \n  this sound much well but I be tempt to ask do god \n  himself exist then if god be the source of his own existence \n  it can only mean that he have in term of human time always \n  exist but this be not the same as the source of all existence \n  this argument sound like god do not exist but metaexist \n  and from his metaexistent perspective he create existence \n  I think this be actually a nonsolution a mere twist of word \n\n always exist and be the source of the existence of all other being \n be not problematic \n\n but as you put be the source of all existence include one own \n would mean that god come from nothing a concept alien to christianity and \n theism   it be well to understand the classical concept of necessary and \n contingent existence   god exist necessarily always   god create \n contingent being   this be a coherent solution to existence so long as \n the concept of god be coherent \n \n  the good answer I have hear be that human reasoning be incapable \n  of understand such question be an atheist myself I do not \n  accept such answer since I do not have any other method \n\n not a very good answer   if reason can not by any mean understand something \n then it be likely that it be a null concept something not in reality \n\n ted kalivoda \n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## For next week\n\n- Create group of 2\n- Ask for your dataset\n- Complete Data cleaning and Processing tasks in the project.",
   "metadata": {
    "tags": [],
    "cell_id": "00034-811ef6ff-28f0-4615-a800-3187b53538fb",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=4b514847-e145-4e51-9c26-e306429d4631' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "deepnote_notebook_id": "17fa0894-0157-4299-b5a8-8fd501cc6354",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}