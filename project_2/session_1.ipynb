{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Session 1 - Data representation from text\n",
    "\n",
    "In this session, we will learn the basics of data representation. You will discover several techniques to represent a document into something that a model can processâ€”learning from the primary count vectorizer to the more complex Tfidf, their differences, and what makes each of them better for a specific use case. We will also cover some data cleaning approaches to avoid treating noise or unnecessary information in our observations.\n",
    "\n",
    "Keywords: *tokenization*, *stop words*, *feature representation*, *count vectorizer*, *tfidf*, *regex*, *feature selection*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overview of the project and the data\n",
    "This project stage focuses on building a classification model to assign a company to its industry using the company description scraped online. We will be discovering how to represent the information to be understood by the machine quickly and find the best method to gain accuracy. You will develop an independent pipeline that will take text as input and give you the closer industry related to your input information during this stage."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's first look at the dataset that we will be using during this whole course using a famous library called [Pandas](https://www.educba.com/what-is-pandas/):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "#Let's import the library\n",
    "import pandas as pd #We define an alias for future usage of the library\n",
    "import re #We will use regex to clean our text\n",
    "from collections import Counter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#We will import and read our dataset using pandas\n",
    "dataset = pd.read_csv(\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Let's now read look at a sample of the data\n",
    "dataset.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are **2** features in this dataset:\n",
    "The name of the company\n",
    "The description of the company. We assumed that we cleaned this text, so no unnecessary information is present in the text. If you want to learn more about this step of cleaning data, refer to stage 1 of this course."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We still have unnecessary information stored in this text. To remove it, we filter and clean the text using regular expressions. Short for regular expression, a regex is a string of text that allows you to create patterns that help match, locate, and manage text."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is an example:\n",
    "\n",
    "![Regular expression](https://www.computerhope.com/jargon/r/regular-expression.gif)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In our case, we don't want to use numbers or special characters because this information can be utilized in any industry and doesn't seem to be a strong marker of knowledge. Let's look at a simple example for the description of Apple"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "description = '''\n",
    "Apple Inc. is an American multinational technology company that specializes in consumer electronics, computer software, and online services. Apple is the world's largest technology company by revenue (totaling $274.5 billion in 2020) and, since January 2021, the world's most valuable company. As of 2021, Apple is the world's fourth-largest PC vendor by unit sales,[9] and fourth-largest smartphone manufacturer.[10][11] It is one of the Big Five American information technology companies, along with Amazon, Google, Microsoft, and Facebook.[12][13][14]\n",
    "\n",
    "Apple was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in 1976 to develop and sell Wozniak's Apple I personal computer. It was incorporated by Jobs and Wozniak as Apple Computer, Inc. in 1977, and sales of its computers, including the Apple II, grew quickly. They went public in 1980 to instant financial success. Over the next few years, Apple shipped new computers featuring innovative graphical user interfaces, such as the original Macintosh, announced with the critically acclaimed advert \"1984\". However, the high price of its products and limited application library caused problems, as did power struggles between executives. In 1985, Wozniak departed Apple amicably,[15] while Jobs resigned to found NeXT, taking some Apple co-workers with him.[16]\n",
    "\n",
    "As the market for personal computers expanded and evolved through the 1990s, Apple lost considerable market share to the lower-priced duopoly of Microsoft Windows on Intel PC clones. The board recruited CEO Gil Amelio, who prepared the struggling company for eventual success with extensive reforms, product focus and layoffs in his 500 day tenure. In 1997, Gil bought NeXT, to resolve Apple's unsuccessful OS strategy and bring back Steve Jobs, who replaced Amelio as CEO later that year. Apple returned to profitability under the revitalizing \"Think different\" campaign, launching the iMac and iPod, opening a retail chain of Apple Stores in 2001, and acquiring numerous companies to broaden their software portfolio. In 2007, the company launched the iPhone to critical acclaim and financial success. In 2011, Jobs resigned as CEO due to health complications, and died two months later. He was succeeded by Tim Cook.\n",
    "\n",
    "In August 2018, Apple became the first publicly traded U.S. company to be valued at over $1 trillion[17][18] and the first valued over $2 trillion two years later.[19][20] It has a high level of brand loyalty and is ranked as the world's most valuable brand; as of January 2021, there are 1.65 billion Apple products in use worldwide.[21] However, the company receives significant criticism regarding the labor practices of its contractors, its environmental practices, and business ethics, including anti-competitive behavior, and materials sourcing. \n",
    "'''\n",
    "description"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nApple Inc. is an American multinational technology company that specializes in consumer electronics, computer software, and online services. Apple is the world\\'s largest technology company by revenue (totaling $274.5 billion in 2020) and, since January 2021, the world\\'s most valuable company. As of 2021, Apple is the world\\'s fourth-largest PC vendor by unit sales,[9] and fourth-largest smartphone manufacturer.[10][11] It is one of the Big Five American information technology companies, along with Amazon, Google, Microsoft, and Facebook.[12][13][14]\\n\\nApple was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in 1976 to develop and sell Wozniak\\'s Apple I personal computer. It was incorporated by Jobs and Wozniak as Apple Computer, Inc. in 1977, and sales of its computers, including the Apple II, grew quickly. They went public in 1980 to instant financial success. Over the next few years, Apple shipped new computers featuring innovative graphical user interfaces, such as the original Macintosh, announced with the critically acclaimed advert \"1984\". However, the high price of its products and limited application library caused problems, as did power struggles between executives. In 1985, Wozniak departed Apple amicably,[15] while Jobs resigned to found NeXT, taking some Apple co-workers with him.[16]\\n\\nAs the market for personal computers expanded and evolved through the 1990s, Apple lost considerable market share to the lower-priced duopoly of Microsoft Windows on Intel PC clones. The board recruited CEO Gil Amelio, who prepared the struggling company for eventual success with extensive reforms, product focus and layoffs in his 500 day tenure. In 1997, Gil bought NeXT, to resolve Apple\\'s unsuccessful OS strategy and bring back Steve Jobs, who replaced Amelio as CEO later that year. Apple returned to profitability under the revitalizing \"Think different\" campaign, launching the iMac and iPod, opening a retail chain of Apple Stores in 2001, and acquiring numerous companies to broaden their software portfolio. In 2007, the company launched the iPhone to critical acclaim and financial success. In 2011, Jobs resigned as CEO due to health complications, and died two months later. He was succeeded by Tim Cook.\\n\\nIn August 2018, Apple became the first publicly traded U.S. company to be valued at over $1 trillion[17][18] and the first valued over $2 trillion two years later.[19][20] It has a high level of brand loyalty and is ranked as the world\\'s most valuable brand; as of January 2021, there are 1.65 billion Apple products in use worldwide.[21] However, the company receives significant criticism regarding the labor practices of its contractors, its environmental practices, and business ethics, including anti-competitive behavior, and materials sourcing. \\n'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "description = re.sub(\"[^A-Za-z]+\", \" \", description) #Replace all element in the text that are not letters\n",
    "description"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' Apple Inc is an American multinational technology company that specializes in consumer electronics computer software and online services Apple is the world s largest technology company by revenue totaling billion in and since January the world s most valuable company As of Apple is the world s fourth largest PC vendor by unit sales and fourth largest smartphone manufacturer It is one of the Big Five American information technology companies along with Amazon Google Microsoft and Facebook Apple was founded by Steve Jobs Steve Wozniak and Ronald Wayne in to develop and sell Wozniak s Apple I personal computer It was incorporated by Jobs and Wozniak as Apple Computer Inc in and sales of its computers including the Apple II grew quickly They went public in to instant financial success Over the next few years Apple shipped new computers featuring innovative graphical user interfaces such as the original Macintosh announced with the critically acclaimed advert However the high price of its products and limited application library caused problems as did power struggles between executives In Wozniak departed Apple amicably while Jobs resigned to found NeXT taking some Apple co workers with him As the market for personal computers expanded and evolved through the s Apple lost considerable market share to the lower priced duopoly of Microsoft Windows on Intel PC clones The board recruited CEO Gil Amelio who prepared the struggling company for eventual success with extensive reforms product focus and layoffs in his day tenure In Gil bought NeXT to resolve Apple s unsuccessful OS strategy and bring back Steve Jobs who replaced Amelio as CEO later that year Apple returned to profitability under the revitalizing Think different campaign launching the iMac and iPod opening a retail chain of Apple Stores in and acquiring numerous companies to broaden their software portfolio In the company launched the iPhone to critical acclaim and financial success In Jobs resigned as CEO due to health complications and died two months later He was succeeded by Tim Cook In August Apple became the first publicly traded U S company to be valued at over trillion and the first valued over trillion two years later It has a high level of brand loyalty and is ranked as the world s most valuable brand as of January there are billion Apple products in use worldwide However the company receives significant criticism regarding the labor practices of its contractors its environmental practices and business ethics including anti competitive behavior and materials sourcing '"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How do you represent text for machine learning?\n",
    "We need to transform the text to make it understandable by a machine learning algorithm.\n",
    "\n",
    "- We will start by converting the text as a sequence of words, also known as tokens"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "review_1 = \"I really liked this Movie\"\n",
    "review_2 = \"This was a terrible movie !\"\n",
    "review_3 = \"I used to like these action movies, now they are boring ...\"\n",
    "\n",
    "\n",
    "review_1.split(\" \")\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['I', 'really', 'liked', 'this', 'Movie']"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- The machine learning algorithm can't understand the information as is it because there are unlimited number of word it will have to learn from. That's why we need to create a custom dictionnary to store each word and transform each sentence as a vector that will count our token. To create that dictionnary, we can use a set that will store new word as soon as they are read by the system:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "source": [
    "vocabulary = set()\n",
    "vocabulary.update(review_1.split(\" \"))\n",
    "vocabulary\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'I', 'Movie', 'liked', 'really', 'this'}"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, you can see that we updated our vocabulary with new token from the first review, let's keep updating it with new token from the other reviews."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "vocabulary.update(review_2.split(\" \"))\n",
    "vocabulary.update(review_3.split(\" \"))\n",
    "print(f\"The size of the vocabulary is {len(vocabulary)} tokens.\")\n",
    "print(f\"Here are the token that composed it: {vocabulary}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The size of the vocabulary is 22 tokens.\n",
      "Here are the token that composed it: {'these', 'movie', '!', 'really', 'are', '...', 'action', 'a', 'Movie', 'now', 'movies,', 'to', 'This', 'boring', 'was', 'they', 'I', 'terrible', 'used', 'like', 'liked', 'this'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, you can see that each new token observed from the system is added to the vocabulary."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Why do we need to clean our text?\n",
    "\n",
    "When creating our vocabulary, we can noticed that a lot of words with the same meaning have been added as discting ententies even if they are the same type of information.\n",
    "\n",
    "Let's try to reduce the vocabulary so words of the same meaning can be represented by the same index in our dictionary.\n",
    "\n",
    "- First let's look at the capital letters, Movie and movie are consider as discting piece of information even if they mean the same thing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "# For simplicity, let's regroup each review in a list\n",
    "reviews = [review_1, review_2, review_3]\n",
    "reviews = [review.lower() for review in reviews]\n",
    "reviews = [review.split(\" \") for review in reviews]\n",
    "print(reviews)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['i', 'really', 'liked', 'this', 'movie'], ['this', 'was', 'a', 'terrible', 'movie', '!'], ['i', 'used', 'to', 'like', 'these', 'action', 'movies,', 'now', 'they', 'are', 'boring', '...']]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "#Let's create a new vocabulary with these reviews\n",
    "vocabulary = set()\n",
    "for tokens in reviews:\n",
    "    vocabulary.update(tokens)\n",
    "print(f\"The size of the vocabulary is {len(vocabulary)} tokens.\")\n",
    "print(f\"Here are the token that composed it: {vocabulary}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The size of the vocabulary is 20 tokens.\n",
      "Here are the token that composed it: {'these', 'movie', '!', 'really', 'are', '...', 'action', 'a', 'i', 'now', 'movies,', 'to', 'boring', 'was', 'they', 'terrible', 'used', 'like', 'liked', 'this'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see; updating all the reviews to be lower case helped us to reduce our vocabulary size. Make it more optimal for the model we will be building."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Which other transformation can be done on the data to optimize the vocabulary?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Let's try to normalize our text a bit more in order to reduce the vocabulary size a bit more.\n",
    "\n",
    "We can use a technique call stemming that will keep the root of each words instead of the whole form. As the example, with the word play:\n",
    "![play](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1539984207/stemminglemmatization_n8bmou.jpg)\n",
    "\n",
    "\n",
    "Let's use a famous NLP library to import a Stemmer to normalize our text called NLTK (Natural Language Tool Kit)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "stemmer = PorterStemmer() # PorterStemmer is a type of stemmer that can be used to normalize text\n",
    "tokens = [[stemmer.stem(token) for token in review] for review in reviews]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "print(reviews)\n",
    "print(tokens)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['i', 'really', 'liked', 'this', 'movie'], ['this', 'was', 'a', 'terrible', 'movie', '!'], ['i', 'used', 'to', 'like', 'these', 'action', 'movies,', 'now', 'they', 'are', 'boring', '...']]\n",
      "[['i', 'realli', 'like', 'thi', 'movi'], ['thi', 'wa', 'a', 'terribl', 'movi', '!'], ['i', 'use', 'to', 'like', 'these', 'action', 'movies,', 'now', 'they', 'are', 'bore', '...']]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "# Let's now look at our new vocabulary\n",
    "vocabulary = set()\n",
    "for token in tokens:\n",
    "    vocabulary.update(token)\n",
    "print(f\"The size of the vocabulary is {len(vocabulary)} tokens.\")\n",
    "print(f\"Here are the token that composed it: {vocabulary}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The size of the vocabulary is 19 tokens.\n",
      "Here are the token that composed it: {'these', '!', 'are', '...', 'realli', 'action', 'a', 'terribl', 'wa', 'i', 'now', 'to', 'movies,', 'movi', 'thi', 'use', 'they', 'bore', 'like'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see in this data normalization process, we reduced our vocabulary by a little but imaging how much optimization it can be with bigger corpus of sentences.\n",
    "\n",
    "## Stopwords\n",
    "\n",
    "When working with an Natural Language Processing, you usually want to avoid using unnecessary features in our input, this can be done with several steps of normalization studied above. One additional normalization is usally performed when dealing with classification problem or topic modeling. This normalization step consist of removing what we call \"stopwords\". Stopwords are pieces of information or words that are common for any types of sentence and that won't useful information for our model. For instance, a stopword can be simple verbs, preprosition, or can even depend on your usecase. You have to think carefully before removing stopwords, in some problems, they can be really useful; for instance expressing feeling with negation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "# Let's import from stopwords in order to clean our sentences\n",
    "nltk.download(\"stopwords\") #We first need to download our stopwords\n",
    "from nltk.corpus import stopwords"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/antoinegargot/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "#Let's have a look at our stopwords\n",
    "stopwords = stopwords.words(\"english\")\n",
    "print(stopwords)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "#We need to stem these stop words to match the stemmer we used in our normalization step above\n",
    "stopwords = [stemmer.stem(word) for word in stopwords]\n",
    "\n",
    "# Now, let's filter out stopwords from all our sentences.\n",
    "tokens = [[token for token in review if token not in stopwords] for review in tokens]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "source": [
    "# Let's now look at our final vocabulary\n",
    "vocabulary = set()\n",
    "for token in tokens:\n",
    "    vocabulary.update(token)\n",
    "print(f\"The size of the vocabulary is {len(vocabulary)} tokens.\")\n",
    "print(f\"Here are the token that composed it: {vocabulary}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The size of the vocabulary is 10 tokens.\n",
      "Here are the token that composed it: {'action', '!', 'bore', 'use', 'terribl', '...', 'like', 'realli', 'movies,', 'movi'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Woah! We started with 21 words in our vocabulary to finish with only 10 tokens. This is a really good optimization of the size of our dictionnary."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transforming text into features\n",
    "\n",
    "Now, that we finished learning how to clean and process our data, we can represent it in a way our model will understand it. We want to transform our sentence into a vector that will be understood by the model, in order to create that vector we will have to use our dictionnary, the simplest way to do it is to count the words that are present in our vocabulary from the sentence.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "# Let's transform our vocabulary into a dictionnary for easier reading\n",
    "voc = {word: index for index, word in enumerate(vocabulary)}\n",
    "print(voc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'action': 0, '!': 1, 'bore': 2, 'use': 3, 'terribl': 4, '...': 5, 'like': 6, 'realli': 7, 'movies,': 8, 'movi': 9}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "#Let's look at our first sentence:\n",
    "review1 = tokens[0]\n",
    "\n",
    "print(review1)\n",
    "\n",
    "#Let's count the number of token that compose this sentence\n",
    "features = [0 for _ in voc]\n",
    "\n",
    "for token in review1:\n",
    "    features[voc[token]] += 1\n",
    "\n",
    "print(features)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['realli', 'like', 'movi']\n",
      "[0, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}